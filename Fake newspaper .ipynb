{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import matplotlib.patches as patches\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from scipy import interp\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import re\n",
    "from wordcloud import WordCloud\n",
    "import liwc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer, HashingVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB,GaussianNB\n",
    "import itertools\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier,LogisticRegression\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.layers import Embedding,LSTM,Dense,Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "liwcPath = r'LIWC2015 Dictionary.dic'\n",
    "parse, category_names = liwc.load_token_parser(liwcPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def tokenize(text):\n",
    "    # you may want to use a smarter tokenizer\n",
    "    for match in re.finditer(r'\\w+', text, re.UNICODE):\n",
    "        yield match.group(0)\n",
    "\n",
    "gettysburg = '''Four score and seven years ago our fathers brought forth on\n",
    "  this continent a new nation, conceived in liberty, and dedicated to the\n",
    "  proposition that all men are created equal. Now we are engaged in a great\n",
    "  civil war, testing whether that nation, or any nation so conceived and so\n",
    "  dedicated, can long endure. We are met on a great battlefield of that war.\n",
    "  We have come to dedicate a portion of that field, as a final resting place\n",
    "  for those who here gave their lives that that nation might live. It is\n",
    "  altogether fitting and proper that we should do this.'''.lower()\n",
    "gettysburg_tokens = tokenize(gettysburg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['number', 'drives', 'reward', 'function', 'conj', 'number', 'relativ', 'time', 'focuspast', 'relativ', 'time', 'function', 'pronoun', 'ppron', 'we', 'social', 'drives', 'affiliation', 'social', 'family', 'male', 'verb', 'focuspast', 'relativ', 'motion', 'function', 'prep', 'relativ', 'space', 'function', 'pronoun', 'ipron', 'function', 'article', 'adj', 'relativ', 'time', 'relativ', 'space', 'function', 'prep', 'relativ', 'space', 'affect', 'posemo', 'function', 'conj', 'adj', 'function', 'prep', 'function', 'article', 'function', 'pronoun', 'ipron', 'quant', 'cogproc', 'certain', 'social', 'male', 'function', 'auxverb', 'verb', 'focuspresent', 'verb', 'affect', 'posemo', 'cogproc', 'cause', 'drives', 'achiev', 'focuspast', 'adj', 'compare', 'quant', 'function', 'adverb', 'focuspresent', 'relativ', 'time', 'function', 'pronoun', 'ppron', 'we', 'social', 'drives', 'affiliation', 'function', 'auxverb', 'verb', 'focuspresent', 'affect', 'posemo', 'social', 'function', 'prep', 'relativ', 'space', 'function', 'article', 'adj', 'affect', 'posemo', 'drives', 'reward', 'affect', 'negemo', 'anger', 'drives', 'power', 'death', 'verb', 'work', 'function', 'conj', 'interrog', 'cogproc', 'differ', 'function', 'pronoun', 'ipron', 'relativ', 'space', 'function', 'conj', 'cogproc', 'tentat', 'differ', 'quant', 'cogproc', 'tentat', 'relativ', 'space', 'function', 'adverb', 'conj', 'function', 'conj', 'function', 'adverb', 'conj', 'adj', 'function', 'auxverb', 'focuspresent', 'relativ', 'space', 'function', 'pronoun', 'ppron', 'we', 'social', 'drives', 'affiliation', 'function', 'auxverb', 'verb', 'focuspresent', 'verb', 'social', 'drives', 'affiliation', 'focuspast', 'function', 'prep', 'relativ', 'space', 'function', 'article', 'adj', 'affect', 'posemo', 'drives', 'reward', 'affect', 'negemo', 'anger', 'drives', 'power', 'function', 'prep', 'function', 'pronoun', 'ipron', 'affect', 'negemo', 'anger', 'drives', 'power', 'death', 'function', 'pronoun', 'ppron', 'we', 'social', 'drives', 'affiliation', 'function', 'auxverb', 'verb', 'focuspresent', 'verb', 'focuspresent', 'relativ', 'motion', 'function', 'prep', 'function', 'article', 'function', 'prep', 'function', 'pronoun', 'ipron', 'function', 'prep', 'conj', 'adj', 'compare', 'function', 'article', 'adj', 'relativ', 'time', 'verb', 'leisure', 'relativ', 'space', 'function', 'prep', 'function', 'pronoun', 'ipron', 'function', 'pronoun', 'ipron', 'interrog', 'social', 'function', 'adverb', 'verb', 'social', 'focuspast', 'function', 'pronoun', 'ppron', 'they', 'social', 'verb', 'bio', 'health', 'focuspresent', 'function', 'pronoun', 'ipron', 'function', 'pronoun', 'ipron', 'relativ', 'space', 'function', 'auxverb', 'verb', 'cogproc', 'tentat', 'focusfuture', 'verb', 'bio', 'health', 'focuspresent', 'function', 'pronoun', 'ipron', 'function', 'auxverb', 'verb', 'focuspresent', 'cogproc', 'certain', 'function', 'conj', 'function', 'pronoun', 'ipron', 'function', 'pronoun', 'ppron', 'we', 'social', 'drives', 'affiliation', 'function', 'auxverb', 'verb', 'cogproc', 'discrep', 'function', 'auxverb', 'verb', 'focuspresent', 'function', 'pronoun', 'ipron']\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "gettysburg_counts = [category for token in gettysburg_tokens for category in parse(token)]\n",
    "print(gettysburg_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(r'Fake and real news dataset\\Fake.csv')\n",
    "df1=pd.read_csv(r'Fake News\\train.csv')\n",
    "df2=pd.read_csv(r'Fake News\\test.csv')\n",
    "df3=pd.read_csv(r'Fake News detection\\data.csv')\n",
    "df4=pd.read_csv(r'Fake and real news dataset\\True.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20800</td>\n",
       "      <td>Specter of Trump Loosens Tongues, if Not Purse...</td>\n",
       "      <td>David Streitfeld</td>\n",
       "      <td>PALO ALTO, Calif.  —   After years of scorning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20801</td>\n",
       "      <td>Russian warships ready to strike terrorists ne...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Russian warships ready to strike terrorists ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20802</td>\n",
       "      <td>#NoDAPL: Native American Leaders Vow to Stay A...</td>\n",
       "      <td>Common Dreams</td>\n",
       "      <td>Videos #NoDAPL: Native American Leaders Vow to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20803</td>\n",
       "      <td>Tim Tebow Will Attempt Another Comeback, This ...</td>\n",
       "      <td>Daniel Victor</td>\n",
       "      <td>If at first you don’t succeed, try a different...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20804</td>\n",
       "      <td>Keiser Report: Meme Wars (E995)</td>\n",
       "      <td>Truth Broadcast Network</td>\n",
       "      <td>42 mins ago 1 Views 0 Comments 0 Likes 'For th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5195</th>\n",
       "      <td>25995</td>\n",
       "      <td>The Bangladeshi Traffic Jam That Never Ends - ...</td>\n",
       "      <td>Jody Rosen</td>\n",
       "      <td>Of all the dysfunctions that plague the world’...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5196</th>\n",
       "      <td>25996</td>\n",
       "      <td>John Kasich Signs One Abortion Bill in Ohio bu...</td>\n",
       "      <td>Sheryl Gay Stolberg</td>\n",
       "      <td>WASHINGTON  —   Gov. John Kasich of Ohio on Tu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5197</th>\n",
       "      <td>25997</td>\n",
       "      <td>California Today: What, Exactly, Is in Your Su...</td>\n",
       "      <td>Mike McPhate</td>\n",
       "      <td>Good morning. (Want to get California Today by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5198</th>\n",
       "      <td>25998</td>\n",
       "      <td>300 US Marines To Be Deployed To Russian Borde...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>« Previous - Next » 300 US Marines To Be Deplo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5199</th>\n",
       "      <td>25999</td>\n",
       "      <td>Awkward Sex, Onscreen and Off - The New York T...</td>\n",
       "      <td>Teddy Wayne</td>\n",
       "      <td>Perhaps you’ve seen the new TV series whose pi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5200 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                              title  \\\n",
       "0     20800  Specter of Trump Loosens Tongues, if Not Purse...   \n",
       "1     20801  Russian warships ready to strike terrorists ne...   \n",
       "2     20802  #NoDAPL: Native American Leaders Vow to Stay A...   \n",
       "3     20803  Tim Tebow Will Attempt Another Comeback, This ...   \n",
       "4     20804                    Keiser Report: Meme Wars (E995)   \n",
       "...     ...                                                ...   \n",
       "5195  25995  The Bangladeshi Traffic Jam That Never Ends - ...   \n",
       "5196  25996  John Kasich Signs One Abortion Bill in Ohio bu...   \n",
       "5197  25997  California Today: What, Exactly, Is in Your Su...   \n",
       "5198  25998  300 US Marines To Be Deployed To Russian Borde...   \n",
       "5199  25999  Awkward Sex, Onscreen and Off - The New York T...   \n",
       "\n",
       "                       author  \\\n",
       "0            David Streitfeld   \n",
       "1                         NaN   \n",
       "2               Common Dreams   \n",
       "3               Daniel Victor   \n",
       "4     Truth Broadcast Network   \n",
       "...                       ...   \n",
       "5195               Jody Rosen   \n",
       "5196      Sheryl Gay Stolberg   \n",
       "5197             Mike McPhate   \n",
       "5198                      NaN   \n",
       "5199              Teddy Wayne   \n",
       "\n",
       "                                                   text  \n",
       "0     PALO ALTO, Calif.  —   After years of scorning...  \n",
       "1     Russian warships ready to strike terrorists ne...  \n",
       "2     Videos #NoDAPL: Native American Leaders Vow to...  \n",
       "3     If at first you don’t succeed, try a different...  \n",
       "4     42 mins ago 1 Views 0 Comments 0 Likes 'For th...  \n",
       "...                                                 ...  \n",
       "5195  Of all the dysfunctions that plague the world’...  \n",
       "5196  WASHINGTON  —   Gov. John Kasich of Ohio on Tu...  \n",
       "5197  Good morning. (Want to get California Today by...  \n",
       "5198  « Previous - Next » 300 US Marines To Be Deplo...  \n",
       "5199  Perhaps you’ve seen the new TV series whose pi...  \n",
       "\n",
       "[5200 rows x 4 columns]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake_ds=pd.concat([df,df4]).drop(['title','subject','date'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake1_ds=df1.drop(['id','title','author'],axis=1).rename({'label':'Label'},axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake2_ds=df3.drop(['URLs','Headline'],axis=1).rename({'Body':'text'},axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_news_Df=pd.concat([df_fake_ds,df_fake1_ds,df_fake2_ds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4004</th>\n",
       "      <td>Trends to Watch\\n% of readers think this story...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4005</th>\n",
       "      <td>Trump Jr. Is Soon To Give A 30-Minute Speech F...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4006</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4007</th>\n",
       "      <td>SHANGHAI (Reuters) - China said it plans to ac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4008</th>\n",
       "      <td>Vice President Mike Pence Leaves NFL Game Beca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69707 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  Label\n",
       "0     Donald Trump just couldn t wish all Americans ...      1\n",
       "1     House Intelligence Committee Chairman Devin Nu...      1\n",
       "2     On Friday, it was revealed that former Milwauk...      1\n",
       "3     On Christmas day, Donald Trump announced that ...      1\n",
       "4     Pope Francis used his annual Christmas Day mes...      1\n",
       "...                                                 ...    ...\n",
       "4004  Trends to Watch\\n% of readers think this story...      0\n",
       "4005  Trump Jr. Is Soon To Give A 30-Minute Speech F...      0\n",
       "4006                                                NaN      0\n",
       "4007  SHANGHAI (Reuters) - China said it plans to ac...      1\n",
       "4008  Vice President Mike Pence Leaves NFL Game Beca...      0\n",
       "\n",
       "[69707 rows x 2 columns]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_news_Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_news_Df = fake_news_Df.dropna()\n",
    "fake_news_Df.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69642</th>\n",
       "      <td>4003</td>\n",
       "      <td>Vietnam Is in Great Danger, You Must Publish a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69643</th>\n",
       "      <td>4004</td>\n",
       "      <td>Trends to Watch\\n% of readers think this story...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69644</th>\n",
       "      <td>4005</td>\n",
       "      <td>Trump Jr. Is Soon To Give A 30-Minute Speech F...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69645</th>\n",
       "      <td>4007</td>\n",
       "      <td>SHANGHAI (Reuters) - China said it plans to ac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69646</th>\n",
       "      <td>4008</td>\n",
       "      <td>Vice President Mike Pence Leaves NFL Game Beca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69647 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                               text  Label\n",
       "0          0  Donald Trump just couldn t wish all Americans ...      1\n",
       "1          1  House Intelligence Committee Chairman Devin Nu...      1\n",
       "2          2  On Friday, it was revealed that former Milwauk...      1\n",
       "3          3  On Christmas day, Donald Trump announced that ...      1\n",
       "4          4  Pope Francis used his annual Christmas Day mes...      1\n",
       "...      ...                                                ...    ...\n",
       "69642   4003  Vietnam Is in Great Danger, You Must Publish a...      0\n",
       "69643   4004  Trends to Watch\\n% of readers think this story...      0\n",
       "69644   4005  Trump Jr. Is Soon To Give A 30-Minute Speech F...      0\n",
       "69645   4007  SHANGHAI (Reuters) - China said it plans to ac...      1\n",
       "69646   4008  Vice President Mike Pence Leaves NFL Game Beca...      0\n",
       "\n",
       "[69647 rows x 3 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_news_Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "words = []\n",
    "for i in range(0,len(df_test)):\n",
    "    review = re.sub('[^a-zA-Z0-9]',' ',df_test['text'].iloc[i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = list(Counter(category for token in review for category in parse(token)))\n",
    "    statements = ' '.join(review)\n",
    "    corpus.append(statements)\n",
    "    words.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = CountVectorizer(max_features=93,ngram_range=(1,3))\n",
    "X_count = count.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>achiev</th>\n",
       "      <th>adj</th>\n",
       "      <th>adj compare</th>\n",
       "      <th>adverb</th>\n",
       "      <th>affect</th>\n",
       "      <th>affect negemo</th>\n",
       "      <th>affect posemo</th>\n",
       "      <th>affiliation</th>\n",
       "      <th>anger</th>\n",
       "      <th>anx</th>\n",
       "      <th>...</th>\n",
       "      <th>social</th>\n",
       "      <th>space</th>\n",
       "      <th>tentat</th>\n",
       "      <th>they</th>\n",
       "      <th>time</th>\n",
       "      <th>verb</th>\n",
       "      <th>verb focuspresent</th>\n",
       "      <th>we</th>\n",
       "      <th>work</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5188</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5189</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5190</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5193 rows × 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      achiev  adj  adj compare  adverb  affect  affect negemo  affect posemo  \\\n",
       "0          1    1            1       1       1              1              0   \n",
       "1          1    1            1       1       1              0              1   \n",
       "2          1    1            0       1       1              1              0   \n",
       "3          1    1            1       1       1              0              1   \n",
       "4          1    1            0       1       1              0              1   \n",
       "...      ...  ...          ...     ...     ...            ...            ...   \n",
       "5188       1    1            1       1       1              1              0   \n",
       "5189       1    1            1       1       1              0              1   \n",
       "5190       1    1            1       1       1              0              1   \n",
       "5191       1    1            0       1       1              1              0   \n",
       "5192       1    1            0       1       1              1              0   \n",
       "\n",
       "      affiliation  anger  anx  ...  social  space  tentat  they  time  verb  \\\n",
       "0               1      1    1  ...       1      1       1     1     1     1   \n",
       "1               1      1    1  ...       1      1       0     1     1     1   \n",
       "2               1      1    1  ...       1      1       1     1     1     1   \n",
       "3               1      0    0  ...       1      1       1     0     1     1   \n",
       "4               1      0    0  ...       1      1       0     0     1     1   \n",
       "...           ...    ...  ...  ...     ...    ...     ...   ...   ...   ...   \n",
       "5188            1      1    1  ...       1      1       1     1     1     1   \n",
       "5189            1      1    1  ...       1      1       1     1     1     1   \n",
       "5190            1      1    1  ...       1      1       1     1     1     1   \n",
       "5191            1      1    1  ...       1      1       1     1     1     1   \n",
       "5192            1      1    1  ...       1      1       1     1     1     1   \n",
       "\n",
       "      verb focuspresent  we  work  you  \n",
       "0                     1   1     1    1  \n",
       "1                     0   0     1    0  \n",
       "2                     1   1     1    0  \n",
       "3                     1   0     1    1  \n",
       "4                     0   1     1    1  \n",
       "...                 ...  ..   ...  ...  \n",
       "5188                  0   1     1    1  \n",
       "5189                  0   1     1    0  \n",
       "5190                  0   1     1    1  \n",
       "5191                  1   1     1    1  \n",
       "5192                  0   1     1    1  \n",
       "\n",
       "[5193 rows x 93 columns]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_count = pd.DataFrame(X_count,columns = count.get_feature_names())\n",
    "df_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=fake_news_Df.Label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>achiev</th>\n",
       "      <th>adj</th>\n",
       "      <th>adj compare</th>\n",
       "      <th>adverb</th>\n",
       "      <th>affect</th>\n",
       "      <th>affect negemo</th>\n",
       "      <th>affect posemo</th>\n",
       "      <th>affiliation</th>\n",
       "      <th>anger</th>\n",
       "      <th>anx</th>\n",
       "      <th>...</th>\n",
       "      <th>tentat</th>\n",
       "      <th>they</th>\n",
       "      <th>time</th>\n",
       "      <th>verb</th>\n",
       "      <th>verb focuspresent</th>\n",
       "      <th>we</th>\n",
       "      <th>work</th>\n",
       "      <th>you</th>\n",
       "      <th>you informal</th>\n",
       "      <th>you informal netspeak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33670</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19331</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14006</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63915</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46068</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37194</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54886</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48752 rows × 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       achiev  adj  adj compare  adverb  affect  affect negemo  affect posemo  \\\n",
       "33670       1    1            1       1       1              0              1   \n",
       "19331       1    1            0       1       1              1              0   \n",
       "14006       0    1            0       1       1              1              0   \n",
       "63915       1    1            0       1       1              0              1   \n",
       "46068       1    1            0       1       1              0              1   \n",
       "...       ...  ...          ...     ...     ...            ...            ...   \n",
       "37194       1    1            0       1       1              0              1   \n",
       "6265        1    1            0       1       1              1              0   \n",
       "54886       1    1            1       1       1              0              1   \n",
       "860         1    1            0       1       1              1              0   \n",
       "15795       1    1            1       1       1              1              0   \n",
       "\n",
       "       affiliation  anger  anx  ...  tentat  they  time  verb  \\\n",
       "33670            1      1    1  ...       1     1     1     1   \n",
       "19331            1      1    1  ...       1     1     1     1   \n",
       "14006            1      1    1  ...       1     1     1     1   \n",
       "63915            1      1    1  ...       1     1     1     1   \n",
       "46068            1      1    1  ...       1     1     1     1   \n",
       "...            ...    ...  ...  ...     ...   ...   ...   ...   \n",
       "37194            1      1    0  ...       1     1     1     1   \n",
       "6265             1      1    0  ...       1     0     1     1   \n",
       "54886            1      1    1  ...       1     1     1     1   \n",
       "860              1      1    1  ...       1     1     1     1   \n",
       "15795            1      0    0  ...       1     0     1     1   \n",
       "\n",
       "       verb focuspresent  we  work  you  you informal  you informal netspeak  \n",
       "33670                  0   1     1    1             1                      1  \n",
       "19331                  1   0     1    1             0                      0  \n",
       "14006                  0   1     0    0             0                      0  \n",
       "63915                  0   1     1    0             0                      0  \n",
       "46068                  0   1     1    1             0                      0  \n",
       "...                  ...  ..   ...  ...           ...                    ...  \n",
       "37194                  0   1     1    0             0                      0  \n",
       "6265                   0   0     1    1             0                      0  \n",
       "54886                  1   1     1    1             0                      0  \n",
       "860                    1   1     1    1             0                      0  \n",
       "15795                  0   1     1    1             1                      1  \n",
       "\n",
       "[48752 rows x 93 columns]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    models['lr'] = LogisticRegression()\n",
    "    models['knn'] = KNeighborsClassifier()\n",
    "    models['cart'] = DecisionTreeClassifier()\n",
    "    models['svm'] = SVC()\n",
    "    models['NN']=MLPClassifier()\n",
    "    models['RF']=RandomForestClassifier()\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification name is lr\n",
      "classification name is knn\n",
      "classification name is cart\n",
      "classification name is svm\n",
      "classification name is NN\n",
      "classification name is RF\n",
      "['lr', 'knn', 'cart', 'svm', 'NN', 'RF']\n",
      "[0.7319454414931802, 0.7249581239530988, 0.7191672648959081, 0.7725771715721464, 0.7558746111509931, 0.7932998324958124]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    result=model.score(X_test, y_test)\n",
    "    results.append(result)\n",
    "    names.append(name)\n",
    "    filename = '{}_model.sav'.format(name)\n",
    "    joblib.dump(model, filename)\n",
    "    print('classification name is',name)\n",
    "    \n",
    "    \n",
    "print(names)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------troll------------\n",
      "lr non-scaled:  0.59\n",
      "--------------------------------\n",
      "knn non-scaled:  0.45\n",
      "--------------------------------\n",
      "cart non-scaled:  0.32\n",
      "--------------------------------\n",
      "svm non-scaled:  0.66\n",
      "--------------------------------\n",
      "NN non-scaled:  0.6\n",
      "--------------------------------\n",
      "RF non-scaled:  0.32\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "#----------troll------------\n",
    "print('----------troll------------')\n",
    "models = get_models()\n",
    "\n",
    "X['Labels']=1\n",
    "x= X.drop(['Labels'],axis=1)\n",
    "y= X.Labels.values\n",
    "\n",
    "for name, model in models.items():\n",
    "    \n",
    "\n",
    "    filename = '{}_model.sav'.format(name)\n",
    "    # load the model from disk\n",
    "    loaded_model = joblib.load(filename)\n",
    "\n",
    "    result = loaded_model.score(x,y)\n",
    "    print('{} non-scaled: '.format(name),round(result,2))\n",
    "\n",
    "    print('--------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------troll------------\n",
      "lr non-scaled:  0.41\n",
      "--------------------------------\n",
      "knn non-scaled:  0.55\n",
      "--------------------------------\n",
      "cart non-scaled:  0.68\n",
      "--------------------------------\n",
      "svm non-scaled:  0.34\n",
      "--------------------------------\n",
      "NN non-scaled:  0.4\n",
      "--------------------------------\n",
      "RF non-scaled:  0.68\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "#----------troll------------\n",
    "print('----------troll------------')\n",
    "models = get_models()\n",
    "\n",
    "X['Labels']=0\n",
    "x= X.drop(['Labels'],axis=1)\n",
    "y= X.Labels.values\n",
    "\n",
    "for name, model in models.items():\n",
    "    \n",
    "\n",
    "    filename = '{}_model.sav'.format(name)\n",
    "    # load the model from disk\n",
    "    loaded_model = joblib.load(filename)\n",
    "\n",
    "    result = loaded_model.score(x,y)\n",
    "    print('{} non-scaled: '.format(name),round(result,2))\n",
    "\n",
    "    print('--------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
